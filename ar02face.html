<!DOCTYPE html>
<html lang="zh-Hant">
<head>
  <meta charset="utf-8">
  <title>Face AR (iPhone16 Pro版)</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

  <style>
    body { margin:0; overflow:hidden; background:black; }
    #video { display:none; }
    #canvas { position:fixed; top:0; left:0; }
    #debug { position:fixed; top:0; left:0; color:#0f0; padding:8px;
             background:rgba(0,0,0,0.4); font-size:14px; }
  </style>

  <!-- Mediapipe：新版 FaceMesh -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh@0.4/face_mesh.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils@0.3/camera_utils.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils@0.3/drawing_utils.js"></script>
</head>

<body>
  <div id="debug">啟動中…請稍等</div>

  <video id="video" playsinline></video>
  <canvas id="canvas"></canvas>

<script>
  const video = document.getElementById("video");
  const canvas = document.getElementById("canvas");
  const ctx = canvas.getContext("2d");
  const debug = document.getElementById("debug");

  async function startCamera(){
    // iPhone 需要 EXACT facingMode + 正確寬高
    const stream = await navigator.mediaDevices.getUserMedia({
      audio:false,
      video:{
        facingMode: "user",
        width: {ideal: 1280},
        height: {ideal: 720}
      }
    });
    video.srcObject = stream;
    await video.play();
  }

  function resize(){
    canvas.width = window.innerWidth;
    canvas.height = window.innerHeight;
  }
  window.onresize = resize;

  async function main(){
    resize();
    await startCamera();
    debug.innerHTML = "相機啟動成功，載入 FaceMesh…";

    const faceMesh = new FaceMesh.FaceMesh({
      locateFile: file => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh@0.4/${file}`
    });

    faceMesh.setOptions({
      maxNumFaces: 1,
      refineLandmarks: true,
      minDetectionConfidence: 0.5,
      minTrackingConfidence: 0.5
    });

    faceMesh.onResults(results => {
      // 畫相機畫面
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

      // 沒臉 → 顯示提示
      if (!results.multiFaceLandmarks || !results.multiFaceLandmarks[0]) {
        debug.innerHTML = "❗ 找不到臉，請把臉靠近鏡頭";
        return;
      }

      debug.innerHTML = "✔ 臉已偵測";

      const face = results.multiFaceLandmarks[0];

      // Example: 眼睛間畫一條線 (測試定位)
      const left = face[33];
      const right = face[263];

      ctx.strokeStyle = "#00ffff";
      ctx.lineWidth = 6;
      ctx.beginPath();
      ctx.moveTo(left.x * canvas.width, left.y * canvas.height);
      ctx.lineTo(right.x * canvas.width, right.y * canvas.height);
      ctx.stroke();
    });

    const camera = new Camera(video, {
      onFrame: async () => {
        await faceMesh.send({image: video});
      },
      width: 1280,
      height: 720
    });
    camera.start();
  }

  main();
</script>

</body>
</html>